# FunASR 转录服务器环境变量配置示例
# 复制此文件为 .env 并根据需要修改配置

# ==================== 服务器配置 ====================
# WebSocket 服务器监听地址
FUNASR_SERVER_HOST=0.0.0.0

# WebSocket 服务器监听端口
FUNASR_SERVER_PORT=8767

# 最大连接数 (可选，覆盖 config.json)
# FUNASR_SERVER_MAX_CONNECTIONS=100

# 最大文件大小限制 MB (可选，覆盖 config.json)
# FUNASR_SERVER_MAX_FILE_SIZE_MB=5000


# ==================== 敏感信息（必需）====================
# 企业微信 Webhook URL
# 格式: https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=your-webhook-key-here
# 如果启用通知功能 (FUNASR_NOTIFICATION_ENABLED=true)，此项必填
FUNASR_WEBHOOK_URL=

# JWT 认证密钥
# 如果启用认证功能 (FUNASR_AUTH_ENABLED=true)，生产环境务必修改此密钥！
FUNASR_AUTH_SECRET_KEY=your-secret-key-change-this-in-production


# ==================== 功能开关 ====================
# 是否启用 JWT 认证 (开发环境: false, 生产环境: true)
FUNASR_AUTH_ENABLED=false

# 是否启用企业微信通知
FUNASR_NOTIFICATION_ENABLED=true


# ==================== 日志配置 ====================
# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
# 开发环境建议 DEBUG，生产环境建议 INFO 或 WARNING
FUNASR_LOG_LEVEL=INFO


# ==================== 目录配置 ====================
# FunASR 模型文件存储目录
FUNASR_MODEL_DIR=./models

# 上传文件临时存储目录
FUNASR_UPLOAD_DIR=./uploads

# 临时文件目录
FUNASR_TEMP_DIR=./temp

# 日志文件存储目录
FUNASR_LOG_DIR=./logs

# 数据库文件存储目录
FUNASR_DATA_DIR=./data


# ==================== FunASR 模型配置 ====================
# 计算设备: auto (自动选择), cpu, dml (Windows GPU), mps (Mac GPU), cuda
# auto 模式会根据 FUNASR_DEVICE_PRIORITY 自动选择可用设备
FUNASR_DEVICE=auto

# 设备优先级 (逗号分隔，无空格)
# Windows: dml,cpu (优先用 DirectML GPU 加速，支持 AMD/NVIDIA/Intel)
# Mac: mps,cpu (优先用 Apple Silicon GPU)
# Linux: cuda,cpu (优先用 NVIDIA GPU)
FUNASR_DEVICE_PRIORITY=dml,mps,cpu

# FunASR 使用的 CPU 线程数 (可选，覆盖 config.json)
# 建议设置为物理核心数
# FUNASR_NCPU=16

# FunASR 批处理大小（秒）(可选，覆盖 config.json)
# 较大的值可以提高吞吐量但会增加内存占用
# FUNASR_BATCH_SIZE_S=500


# ==================== 转录任务配置 ====================
# 最大并发转录任务数 (可选，覆盖 config.json)
# 建议设置为 CPU 核心数的一半，避免过载
# FUNASR_MAX_CONCURRENT_TASKS=2

# 单个任务超时时间（分钟）(可选，覆盖 config.json)
# FUNASR_TASK_TIMEOUT_MINUTES=30


# ==================== 平台特定优化 ====================
# OpenMP 线程数（控制底层并行计算库的线程池大小）
# 说明：
# - 影响 PyTorch、NumPy 等科学计算库的 CPU 并行运算
# - 建议值：CPU 核心数的 1/2 到 1/1（并发场景建议较小值）
# - 过大会导致线程竞争，反而降低性能
# - 过小会浪费 CPU 资源
# 推荐配置：
# - 单任务场景：设置为 CPU 核心数（如 8 核设为 8）
# - 多任务并发：设置为核心数的一半（如 8 核设为 4）
# - 默认：4（适合大多数场景）
OMP_NUM_THREADS=4

# PyTorch MPS 内存管理配置（仅 macOS Apple Silicon GPU 加速时生效）
# 说明：
# - MPS = Metal Performance Shaders（Apple GPU 加速框架）
# - 控制 GPU 内存缓存策略的"高水位线"比例
# - 0.0 = 禁用缓存，每次都释放 GPU 内存
# - 0.3 = 保留 30% 内存作为缓存，提升性能但可能 OOM
# 优势：
# - 0.0 避免长时间运行时的内存碎片化问题
# - 0.0 支持多任务并发时的内存共享
# - 0.0 提高系统稳定性，避免 OOM 崩溃
# 代价：
# - 0.0 会略微降低性能（频繁分配/释放内存）
# 推荐配置：
# - 服务器长时间运行：0.0（稳定性优先）
# - GPU 内存充足且单任务：0.3-0.5（性能优先）
# - 默认：0.0（本项目默认值，已在代码中自动设置）
PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0


# ==================== Docker 配置 ====================
# Docker Compose 项目名称 (仅在 Docker 环境中使用)
# COMPOSE_PROJECT_NAME=funasr
